{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-11T17:59:39.907623Z",
     "iopub.status.busy": "2026-01-11T17:59:39.907166Z",
     "iopub.status.idle": "2026-01-11T17:59:40.157014Z",
     "shell.execute_reply": "2026-01-11T17:59:40.156147Z",
     "shell.execute_reply.started": "2026-01-11T17:59:39.907600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T17:59:50.008374Z",
     "iopub.status.busy": "2026-01-11T17:59:50.007583Z",
     "iopub.status.idle": "2026-01-11T17:59:54.199799Z",
     "shell.execute_reply": "2026-01-11T17:59:54.199072Z",
     "shell.execute_reply.started": "2026-01-11T17:59:50.008350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/boujdour\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dheeraj/kaggle/input/boujdour\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T17:59:56.945376Z",
     "iopub.status.busy": "2026-01-11T17:59:56.944664Z",
     "iopub.status.idle": "2026-01-11T17:59:57.072329Z",
     "shell.execute_reply": "2026-01-11T17:59:57.071555Z",
     "shell.execute_reply.started": "2026-01-11T17:59:56.945349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>zone1</th>\n",
       "      <th>zone2</th>\n",
       "      <th>zone3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14/09/2022 17:10</td>\n",
       "      <td>59,81</td>\n",
       "      <td>14,88</td>\n",
       "      <td>60,77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14/09/2022 17:20</td>\n",
       "      <td>59,68</td>\n",
       "      <td>15,08</td>\n",
       "      <td>60,52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/09/2022 17:30</td>\n",
       "      <td>60,45</td>\n",
       "      <td>15,25</td>\n",
       "      <td>60,63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/09/2022 17:40</td>\n",
       "      <td>59,72</td>\n",
       "      <td>15,15</td>\n",
       "      <td>59,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/09/2022 17:50</td>\n",
       "      <td>60,75</td>\n",
       "      <td>15,60</td>\n",
       "      <td>60,43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateTime  zone1  zone2  zone3\n",
       "0  14/09/2022 17:10  59,81  14,88  60,77\n",
       "1  14/09/2022 17:20  59,68  15,08  60,52\n",
       "2  14/09/2022 17:30  60,45  15,25  60,63\n",
       "3  14/09/2022 17:40  59,72  15,15  59,29\n",
       "4  14/09/2022 17:50  60,75  15,60  60,43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/boujdour/Boujdour 10T.csv', sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:03.367553Z",
     "iopub.status.busy": "2026-01-11T18:00:03.367062Z",
     "iopub.status.idle": "2026-01-11T18:00:03.441057Z",
     "shell.execute_reply": "2026-01-11T18:00:03.440336Z",
     "shell.execute_reply.started": "2026-01-11T18:00:03.367532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns[1:]:\n",
    "  df[col]=df[col].str.replace(\",\",\".\",regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:10.937156Z",
     "iopub.status.busy": "2026-01-11T18:00:10.936878Z",
     "iopub.status.idle": "2026-01-11T18:00:10.973502Z",
     "shell.execute_reply": "2026-01-11T18:00:10.972946Z",
     "shell.execute_reply.started": "2026-01-11T18:00:10.937136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns[1:]:\n",
    "  df[col]=df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:17.248601Z",
     "iopub.status.busy": "2026-01-11T18:00:17.248339Z",
     "iopub.status.idle": "2026-01-11T18:00:17.496729Z",
     "shell.execute_reply": "2026-01-11T18:00:17.496180Z",
     "shell.execute_reply.started": "2026-01-11T18:00:17.248582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure 'DateTime' is datetime type\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Set DateTime as index\n",
    "df = df.set_index('DateTime')\n",
    "\n",
    "# Sort by datetime just in case\n",
    "df = df.sort_index()\n",
    "\n",
    "# Now resampling works\n",
    "data_hourly = df.resample('1h').sum()\n",
    "data_hourly_mean = df.resample('1h').mean()\n",
    "data_daily_mean = data_hourly_mean.resample('1D').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:23.726765Z",
     "iopub.status.busy": "2026-01-11T18:00:23.726501Z",
     "iopub.status.idle": "2026-01-11T18:00:27.864105Z",
     "shell.execute_reply": "2026-01-11T18:00:27.863190Z",
     "shell.execute_reply.started": "2026-01-11T18:00:23.726745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.17.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:30.733660Z",
     "iopub.status.busy": "2026-01-11T18:00:30.732989Z",
     "iopub.status.idle": "2026-01-11T18:00:33.846207Z",
     "shell.execute_reply": "2026-01-11T18:00:33.845262Z",
     "shell.execute_reply.started": "2026-01-11T18:00:30.733631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->lightgbm) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.0->lightgbm) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.0->lightgbm) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:39.453008Z",
     "iopub.status.busy": "2026-01-11T18:00:39.452371Z",
     "iopub.status.idle": "2026-01-11T18:00:43.655582Z",
     "shell.execute_reply": "2026-01-11T18:00:43.654878Z",
     "shell.execute_reply.started": "2026-01-11T18:00:39.452975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.33.0\n",
      "    Uninstalling protobuf-6.33.0:\n",
      "      Successfully uninstalled protobuf-6.33.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-5.29.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:48.119611Z",
     "iopub.status.busy": "2026-01-11T18:00:48.119057Z",
     "iopub.status.idle": "2026-01-11T18:00:51.448770Z",
     "shell.execute_reply": "2026-01-11T18:00:51.447806Z",
     "shell.execute_reply.started": "2026-01-11T18:00:48.119584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install prophet lightgbm optuna tensorflow -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T18:00:54.531142Z",
     "iopub.status.busy": "2026-01-11T18:00:54.530402Z",
     "iopub.status.idle": "2026-01-11T18:02:15.000953Z",
     "shell.execute_reply": "2026-01-11T18:02:15.000129Z",
     "shell.execute_reply.started": "2026-01-11T18:00:54.531113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw hourly data shape: (14816, 3)\n",
      "                         zone1      zone2      zone3\n",
      "DateTime                                            \n",
      "2022-09-14 17:00:00  60.082000  15.192000  60.328000\n",
      "2022-09-14 18:00:00  64.758333  16.280000  58.718333\n",
      "2022-09-14 19:00:00  66.251667  17.761667  54.316667\n",
      "2022-09-14 20:00:00  79.946667  24.691667  64.728333\n",
      "2022-09-14 21:00:00  86.553333  25.910000  70.788333\n",
      "‚úÖ After feature engineering: 70 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/2474188632.py:56: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n",
      "/tmp/ipykernel_47/2474188632.py:56: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n",
      "/tmp/ipykernel_47/2474188632.py:56: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß≠ Prophet detected ‚Äî extracting daily components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:00:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:00:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/tmp/ipykernel_47/2474188632.py:115: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n",
      "2026-01-11 18:00:57.052400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768154457.226625      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768154457.276763      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∂ TensorFlow available ‚Äî training LSTM encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/2474188632.py:152: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_train = df[feature_cols].fillna(method=\"ffill\").fillna(0)\n",
      "I0000 00:00:1768154472.473290      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "I0000 00:00:1768154475.567676     175 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Final engineered DataFrame shape: (14816, 107)\n",
      "‚úÖ Total columns: 107\n",
      "                         zone1      zone2      zone3  hour  dayofweek  month  \\\n",
      "DateTime                                                                       \n",
      "2022-09-14 17:00:00  60.082000  15.192000  60.328000    17          2      9   \n",
      "2022-09-14 18:00:00  64.758333  16.280000  58.718333    18          2      9   \n",
      "2022-09-14 19:00:00  66.251667  17.761667  54.316667    19          2      9   \n",
      "2022-09-14 20:00:00  79.946667  24.691667  64.728333    20          2      9   \n",
      "2022-09-14 21:00:00  86.553333  25.910000  70.788333    21          2      9   \n",
      "\n",
      "                     is_weekend  hour_sin      hour_cos  zone1_lag_1  ...  \\\n",
      "DateTime                                                              ...   \n",
      "2022-09-14 17:00:00           0 -0.965926 -2.588190e-01          NaN  ...   \n",
      "2022-09-14 18:00:00           0 -1.000000 -1.836970e-16    60.082000  ...   \n",
      "2022-09-14 19:00:00           0 -0.965926  2.588190e-01    64.758333  ...   \n",
      "2022-09-14 20:00:00           0 -0.866025  5.000000e-01    66.251667  ...   \n",
      "2022-09-14 21:00:00           0 -0.707107  7.071068e-01    79.946667  ...   \n",
      "\n",
      "                     lstm_emb_22  lstm_emb_23  lstm_emb_24  lstm_emb_25  \\\n",
      "DateTime                                                                  \n",
      "2022-09-14 17:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 18:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 19:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 20:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 21:00:00          NaN          NaN          NaN          NaN   \n",
      "\n",
      "                     lstm_emb_26  lstm_emb_27  lstm_emb_28  lstm_emb_29  \\\n",
      "DateTime                                                                  \n",
      "2022-09-14 17:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 18:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 19:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 20:00:00          NaN          NaN          NaN          NaN   \n",
      "2022-09-14 21:00:00          NaN          NaN          NaN          NaN   \n",
      "\n",
      "                     lstm_emb_30  lstm_emb_31  \n",
      "DateTime                                       \n",
      "2022-09-14 17:00:00          NaN          NaN  \n",
      "2022-09-14 18:00:00          NaN          NaN  \n",
      "2022-09-14 19:00:00          NaN          NaN  \n",
      "2022-09-14 20:00:00          NaN          NaN  \n",
      "2022-09-14 21:00:00          NaN          NaN  \n",
      "\n",
      "[5 rows x 107 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved as final_engineered_df.csv\n"
     ]
    }
   ],
   "source": [
    "# üìò Robust Hybrid Feature Engineering Pipeline\n",
    "# Prophet (Daily) + LSTM (Hourly) + Symbolic & Programmatic Features\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 1Ô∏è‚É£ LOAD AND PREPARE DATA\n",
    "# Assume you already have:\n",
    "#  üîπ data ‚Üí original 10-min resolution dataframe\n",
    "#  üîπ data_hourly_mean ‚Üí hourly mean dataframe (aggregated from data)\n",
    "# Example: data_hourly_mean = data.resample('H').mean()\n",
    "\n",
    "df_hourly = data_hourly_mean.copy()\n",
    "df_hourly.index.name = \"DateTime\"\n",
    "\n",
    "print(f\"Raw hourly data shape: {df_hourly.shape}\")\n",
    "print(df_hourly.head())\n",
    "\n",
    "# 2Ô∏è‚É£ FEATURE ENGINEERING UTILITIES\n",
    "\n",
    "def add_time_features(df):\n",
    "    \"\"\"Add calendar and cyclical time features.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    df[\"dayofweek\"] = df.index.dayofweek\n",
    "    df[\"month\"] = df.index.month\n",
    "    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5,6]).astype(int)\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "    return df\n",
    "\n",
    "def add_lag_and_rolling(df, zones, lags=[1,3,6,12,24], rolls=[3,6,12,24]):\n",
    "    \"\"\"Add lag and rolling statistical features.\"\"\"\n",
    "    df = df.copy()\n",
    "    for z in zones:\n",
    "        for l in lags:\n",
    "            df[f\"{z}_lag_{l}\"] = df[z].shift(l)\n",
    "        for w in rolls:\n",
    "            df[f\"{z}_roll_mean_{w}\"] = df[z].rolling(window=w, min_periods=1).mean()\n",
    "            df[f\"{z}_roll_std_{w}\"] = df[z].rolling(window=w, min_periods=1).std().fillna(0)\n",
    "    return df\n",
    "\n",
    "def add_derivatives(df, zones):\n",
    "    \"\"\"Add first/second derivatives and percentage change.\"\"\"\n",
    "    df = df.copy()\n",
    "    for z in zones:\n",
    "        df[f\"{z}_diff_1\"] = df[z].diff(1)\n",
    "        df[f\"{z}_diff_2\"] = df[z].diff(2)\n",
    "        df[f\"{z}_pct_change_1\"] = df[z].pct_change(1).replace([np.inf,-np.inf], np.nan).fillna(0)\n",
    "    return df\n",
    "\n",
    "def add_fourier_terms(df, period_hours=24, K=3):\n",
    "    \"\"\"Add Fourier seasonal terms.\"\"\"\n",
    "    df = df.copy()\n",
    "    t = np.arange(len(df))\n",
    "    for k in range(1, K+1):\n",
    "        df[f\"fourier_sin_{k}\"] = np.sin(2*np.pi*k*t/period_hours)\n",
    "        df[f\"fourier_cos_{k}\"] = np.cos(2*np.pi*k*t/period_hours)\n",
    "    return df\n",
    "\n",
    "def add_symbolic_like_features(df, zones):\n",
    "    \"\"\"Add interpretable symbolic-like nonlinear feature combinations.\"\"\"\n",
    "    df = df.copy()\n",
    "    for z in zones:\n",
    "        df[f\"{z}_sym_sinlag3_logroll6\"] = np.sin(df[f\"{z}_lag_3\"].fillna(0)) * np.log1p(df[f\"{z}_roll_mean_6\"].fillna(0))\n",
    "        df[f\"{z}_sym_lag1_over_lag24\"] = df[f\"{z}_lag_1\"] / (df[f\"{z}_lag_24\"].replace(0, np.nan))\n",
    "        df[f\"{z}_sym_prod_diff1_diff2\"] = df[f\"{z}_diff_1\"].fillna(0) * df[f\"{z}_diff_2\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "# 3Ô∏è‚É£ APPLY PROGRAMMATIC + SYMBOLIC FEATURE ENGINEERING\n",
    "zones = [c for c in df_hourly.columns if c.startswith(\"zone\")]\n",
    "df = df_hourly.copy()\n",
    "df = add_time_features(df)\n",
    "df = add_lag_and_rolling(df, zones)\n",
    "df = add_derivatives(df, zones)\n",
    "df = add_fourier_terms(df, period_hours=24, K=2)\n",
    "df = add_symbolic_like_features(df, zones)\n",
    "\n",
    "print(f\"‚úÖ After feature engineering: {df.shape[1]} columns\")\n",
    "\n",
    "# 4Ô∏è‚É£ PROPHET-DERIVED DAILY FEATURES (TREND + WEEKLY + YEARLY)\n",
    "\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    prophet_available = True\n",
    "except:\n",
    "    try:\n",
    "        from fbprophet import Prophet\n",
    "        prophet_available = True\n",
    "    except:\n",
    "        prophet_available = False\n",
    "\n",
    "if prophet_available:\n",
    "    print(\"üß≠ Prophet detected ‚Äî extracting daily components...\")\n",
    "    daily = df_hourly.sum(axis=1).resample(\"D\").mean().reset_index()\n",
    "    daily.columns = [\"ds\", \"y\"]\n",
    "\n",
    "    m = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)\n",
    "    m.fit(daily)\n",
    "    forecast = m.predict(m.make_future_dataframe(periods=0, freq=\"D\"))\n",
    "    comp = forecast[[\"ds\", \"trend\", \"weekly\", \"yearly\", \"yhat\"]].set_index(\"ds\")\n",
    "    comp[\"residual\"] = daily.set_index(\"ds\")[\"y\"] - comp[\"yhat\"]\n",
    "\n",
    "    # Upsample to hourly and align with df\n",
    "    comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n",
    "    comp_hourly = comp_hourly.reindex(df.index, method=\"ffill\")\n",
    "    for col in comp_hourly.columns:\n",
    "        df[f\"prophet_{col}\"] = comp_hourly[col].values\n",
    "else:\n",
    "    print(\"‚öôÔ∏è Prophet not available ‚Äî using STL decomposition fallback.\")\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "    daily = df_hourly.sum(axis=1).resample(\"D\").mean()\n",
    "    stl = STL(daily.interpolate(), period=7)\n",
    "    res = stl.fit()\n",
    "    comp = pd.DataFrame({\n",
    "        \"trend\": res.trend,\n",
    "        \"seasonal\": res.seasonal,\n",
    "        \"resid\": res.resid\n",
    "    })\n",
    "    comp_hourly = comp.reindex(pd.date_range(comp.index.min(), comp.index.max(), freq=\"H\")).ffill()\n",
    "    comp_hourly = comp_hourly.reindex(df.index, method=\"ffill\")\n",
    "    df[\"prophet_trend\"] = comp_hourly[\"trend\"].values\n",
    "    df[\"prophet_weekly\"] = comp_hourly[\"seasonal\"].values\n",
    "    df[\"prophet_residual\"] = comp_hourly[\"resid\"].values\n",
    "\n",
    "# 5Ô∏è‚É£ LSTM-DERIVED TEMPORAL EMBEDDINGS (OPTIONAL)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    tf_available = True\n",
    "except:\n",
    "    tf_available = False\n",
    "\n",
    "if tf_available:\n",
    "    print(\"üî∂ TensorFlow available ‚Äî training LSTM encoder...\")\n",
    "    feature_cols = [c for c in df.columns if not c.startswith(\"zone\")] + [f\"{z}_lag_1\" for z in zones]\n",
    "    feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "    df_train = df[feature_cols].fillna(method=\"ffill\").fillna(0)\n",
    "    seq_len = 24  # one-day lookback window\n",
    "\n",
    "    X, y = [], []\n",
    "    total = df_hourly.sum(axis=1)\n",
    "    for i in range(len(df_train)-seq_len):\n",
    "        X.append(df_train.iloc[i:i+seq_len].values)\n",
    "        y.append(total.iloc[i+seq_len])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    if len(X) > 0:\n",
    "        inp = Input(shape=(X.shape[1], X.shape[2]))\n",
    "        lstm_layer = LSTM(32, return_sequences=False, name=\"encoder_lstm\")(inp)\n",
    "        out = Dense(1, activation=\"linear\")(lstm_layer)\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        es = EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)\n",
    "        model.fit(X, y, epochs=30, batch_size=32, callbacks=[es], verbose=0)\n",
    "\n",
    "        encoder = Model(inputs=inp, outputs=model.get_layer(\"encoder_lstm\").output)\n",
    "        embeddings = encoder.predict(X, verbose=0)\n",
    "        emb_df = pd.DataFrame(embeddings, index=df.index[seq_len:seq_len+len(embeddings)])\n",
    "        for i_col in range(emb_df.shape[1]):\n",
    "            df[f\"lstm_emb_{i_col}\"] = np.nan\n",
    "            df.loc[emb_df.index, f\"lstm_emb_{i_col}\"] = emb_df.iloc[:, i_col].values\n",
    "    else:\n",
    "        print(\"Not enough samples for LSTM embedding.\")\n",
    "else:\n",
    "    print(\"‚ùå TensorFlow not available ‚Äî skipping LSTM embedding features.\")\n",
    "\n",
    "# 6Ô∏è‚É£ SAVE & DISPLAY FINAL FEATURE DATASET\n",
    "print(f\"\\n‚úÖ Final engineered DataFrame shape: {df.shape}\")\n",
    "print(f\"‚úÖ Total columns: {len(df.columns)}\")\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"final_engineered_df.csv\")\n",
    "print(\"üíæ Saved as final_engineered_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Robust Hybrid: Prophet + LSTM Weighted Ensemble (fixed sensitivity + improvements)\n",
    "import os, random, time, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from scipy.optimize import minimize_scalar\n",
    "import shap\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# -------------------- Reproducibility --------------------\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# If your TF supports mixed precision and you want it, keep it. Otherwise comment out.\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------- Data (user should provide `data_hourly_mean`) --------------------\n",
    "# df = data_hourly_mean.copy()  # <- expected provided by user\n",
    "# Example: ensure df index is datetime and columns are zones\n",
    "# df.index = pd.to_datetime(df.index)\n",
    "# for col in df.columns: df[col] = df[col].interpolate().bfill().ffill().fillna(df[col].mean())\n",
    "\n",
    "# -------------------- Parameters --------------------\n",
    "train_ratio = 0.8\n",
    "n_lags = 48\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "patience = 15\n",
    "alpha_cpi = 0.05  # 95% conformal interval\n",
    "tscv_splits = 3   # (unused in this script, kept for later CV extension)\n",
    "target_scale_for_lstm = False  # If True: scale target y_train with StandardScaler (can help numeric stability)\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "def train_prophet(series, train_idx):\n",
    "    \"\"\"\n",
    "    Fit Prophet on daily-aggregated training portion and predict daily yhat for whole series range.\n",
    "    Then resample to hourly and align to series index by interpolation.\n",
    "    \"\"\"\n",
    "    train_series = series.iloc[:train_idx]\n",
    "    daily = train_series.resample('D').mean().reset_index()\n",
    "    daily.columns = ['ds', 'y']\n",
    "    daily['y'] = daily['y'].fillna(method='ffill').fillna(method='bfill').fillna(daily['y'].mean())\n",
    "\n",
    "    m = Prophet(\n",
    "        daily_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=False,\n",
    "        seasonality_mode='multiplicative',\n",
    "        changepoint_prior_scale=0.9\n",
    "    )\n",
    "    m.fit(daily)\n",
    "\n",
    "    # Forecast from train end date to end of series (so we have predictions over validation/test)\n",
    "    start = daily['ds'].min()\n",
    "    end = series.index.max().normalize()  # include until max index date\n",
    "    fut = pd.DataFrame({'ds': pd.date_range(start, end, freq='D')})\n",
    "    forecast = m.predict(fut)\n",
    "    # use yhat, then resample to hourly and interpolate to match series index\n",
    "    hourly = forecast.set_index('ds')['yhat'].resample('H').interpolate()\n",
    "    # reindex to exact series index with interpolation\n",
    "    hourly = hourly.reindex(pd.DatetimeIndex(series.index.union(hourly.index))).interpolate().reindex(series.index)\n",
    "    return hourly\n",
    "\n",
    "def create_lag_features(series, n_lags):\n",
    "    feat = pd.DataFrame(index=series.index)\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        feat[f'lag_{lag}'] = series.shift(lag)\n",
    "    # cyclical hour encoding\n",
    "    feat['hour_sin'] = np.sin(2*np.pi*series.index.hour/24)\n",
    "    feat['hour_cos'] = np.cos(2*np.pi*series.index.hour/24)\n",
    "    feat['dow'] = series.index.dayofweek\n",
    "    feat['month'] = series.index.month\n",
    "    feat['is_weekend'] = (series.index.weekday >= 5).astype(int)\n",
    "    feat['trend_24h'] = series.rolling(24, min_periods=1).mean()\n",
    "    feat['roll_mean_12'] = series.rolling(12, min_periods=1).mean()\n",
    "    feat['roll_std_12'] = series.rolling(12, min_periods=1).std().fillna(0)\n",
    "    return feat\n",
    "\n",
    "def build_lstm(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(256, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(128),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, dtype='float32')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(3e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "def make_predict_fn(model):\n",
    "    def predict_fn(X_2d):\n",
    "        X = np.array(X_2d, dtype=np.float32)\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        # expected shape: (n_samples, n_features) -> reshape to (n_samples, n_features, 1)\n",
    "        return model.predict(X.reshape((X.shape[0], X.shape[1], 1)), verbose=0).flatten()\n",
    "    return predict_fn\n",
    "\n",
    "def compute_residual_entropy(residuals, bins=50):\n",
    "    hist, _ = np.histogram(residuals, bins=bins, density=True)\n",
    "    hist = hist + 1e-12  # avoid log(0)\n",
    "    return entropy(hist)\n",
    "\n",
    "def compute_cpi(y_true, y_pred, alpha=0.05):\n",
    "    # compute (1-alpha) quantile of absolute residuals\n",
    "    abs_res = np.abs(y_true - y_pred)\n",
    "    q = np.quantile(abs_res, 1 - alpha)\n",
    "    lower = y_pred - q\n",
    "    upper = y_pred + q\n",
    "    coverage = np.mean((y_true >= lower) & (y_true <= upper))\n",
    "    width = np.mean(upper - lower)\n",
    "    return coverage, width, q\n",
    "\n",
    "# -------------------- Main Loop --------------------\n",
    "def run_hybrid(df):\n",
    "    zones = df.columns.tolist()\n",
    "    print(\"Zones:\", zones, \" NaNs after cleaning:\", df.isna().sum().sum())\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for zone in zones:\n",
    "        print(f\"\\n--- Zone: {zone} ---\")\n",
    "        series = df[zone].astype(float)\n",
    "        n = len(series)\n",
    "        split_idx = int(n * train_ratio)\n",
    "\n",
    "        # Prophet: train on train portion and predict for full period\n",
    "        prophet_pred_series = train_prophet(series, split_idx)\n",
    "\n",
    "        # LSTM features\n",
    "        feat = create_lag_features(series, n_lags)\n",
    "        feat['y_true'] = series\n",
    "        supervised = feat.dropna()\n",
    "        # ensure we still have enough samples\n",
    "        if supervised.shape[0] < 100:\n",
    "            print(\"Warning: too few supervised samples after lagging for zone\", zone)\n",
    "        train_mask = supervised.index < series.index[split_idx]\n",
    "        train_df, val_df = supervised.loc[train_mask], supervised.loc[~train_mask]\n",
    "\n",
    "        X_train = train_df.drop(columns=['y_true']).values.astype(np.float32)\n",
    "        y_train = train_df['y_true'].values.astype(np.float32)\n",
    "        X_val = val_df.drop(columns=['y_true']).values.astype(np.float32)\n",
    "        y_val = val_df['y_true'].values.astype(np.float32)\n",
    "\n",
    "        # scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        # optional: scale target for better numeric stability in LSTM\n",
    "        if target_scale_for_lstm:\n",
    "            y_scaler = StandardScaler().fit(y_train.reshape(-1,1))\n",
    "            y_train_scaled = y_scaler.transform(y_train.reshape(-1,1)).reshape(-1)\n",
    "            # note: at inference, remember to inverse transform predictions\n",
    "        else:\n",
    "            y_train_scaled = y_train.copy()\n",
    "\n",
    "        X_train_3d = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "        X_val_3d = X_val_scaled.reshape((X_val_scaled.shape[0], X_val_scaled.shape[1], 1))\n",
    "\n",
    "        # LSTM model training\n",
    "        lstm_model = build_lstm((X_train_3d.shape[1], 1))\n",
    "        es = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True, verbose=0)\n",
    "        lstm_model.fit(X_train_3d, y_train_scaled, validation_data=(X_val_3d, y_val),\n",
    "                       epochs=epochs, batch_size=batch_size, verbose=0, callbacks=[es])\n",
    "\n",
    "        # Predictions from LSTM\n",
    "        lstm_val_pred = lstm_model.predict(X_val_3d, verbose=0).flatten()\n",
    "        if target_scale_for_lstm:\n",
    "            # inverse transform\n",
    "            lstm_val_pred = y_scaler.inverse_transform(lstm_val_pred.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "        # Prophet val predictions aligned to val_df index\n",
    "        prophet_val_pred = prophet_pred_series.loc[val_df.index].values\n",
    "\n",
    "        # Optimize weight w on validation set\n",
    "        def obj_w(w):\n",
    "            blended = w * prophet_val_pred + (1.0 - w) * lstm_val_pred\n",
    "            return np.sqrt(mean_squared_error(y_val, blended))\n",
    "        res = minimize_scalar(obj_w, bounds=(0.0, 1.0), method='bounded')\n",
    "        w_opt = float(res.x) if res.success else 0.5\n",
    "        hybrid_val_pred = w_opt * prophet_val_pred + (1.0 - w_opt) * lstm_val_pred\n",
    "\n",
    "        # Conformal Prediction Interval (CPI)\n",
    "        cpi_cov, cpi_width, cpi_q = compute_cpi(y_val, hybrid_val_pred, alpha=alpha_cpi)\n",
    "\n",
    "        # SHAP feature importance (try real SHAP, fallback to permutation importance)\n",
    "        shap_series = None\n",
    "        try:\n",
    "            predict_fn = make_predict_fn(lstm_model)\n",
    "            bg_idx = np.random.choice(X_train_scaled.shape[0], min(100, X_train_scaled.shape[0]), replace=False)\n",
    "            X_bg = X_train_scaled[bg_idx]\n",
    "            explainer = shap.Explainer(predict_fn, X_bg)\n",
    "            # limit to first N val rows to speed up\n",
    "            shap_vals = explainer(X_val_sample, max_evals=100)\n",
    "            shap_series = pd.Series(np.mean(np.abs(shap_vals.values), axis=0),\n",
    "                                    index=train_df.drop(columns=['y_true']).columns).sort_values(ascending=False)\n",
    "        except Exception as e:\n",
    "            # fallback: simple permutation importance (correlation-based)\n",
    "            try:\n",
    "                cols = train_df.drop(columns=['y_true']).columns\n",
    "                perm_imp = {}\n",
    "                base_rmse = np.sqrt(mean_squared_error(y_val, lstm_val_pred))\n",
    "                for i, col in enumerate(cols):\n",
    "                    X_val_perm = X_val_scaled.copy()\n",
    "                    np.random.shuffle(X_val_perm[:, i])\n",
    "                    pred_perm = lstm_model.predict(X_val_perm.reshape((X_val_perm.shape[0], X_val_perm.shape[1], 1)), verbose=0).flatten()\n",
    "                    if target_scale_for_lstm:\n",
    "                        pred_perm = y_scaler.inverse_transform(pred_perm.reshape(-1,1)).reshape(-1)\n",
    "                    rmse_perm = np.sqrt(mean_squared_error(y_val, pred_perm))\n",
    "                    perm_imp[col] = rmse_perm - base_rmse\n",
    "                shap_series = pd.Series(perm_imp).sort_values(ascending=False)\n",
    "            except Exception:\n",
    "                shap_series = pd.Series(np.abs(pd.DataFrame(X_train_scaled, columns=train_df.drop(columns=['y_true']).columns).corrwith(pd.Series(y_train))).sort_values(ascending=False))\n",
    "\n",
    "        # Residual entropy\n",
    "        res_entropy = compute_residual_entropy(y_val - hybrid_val_pred)\n",
    "\n",
    "        # ------------ Fixed Perturbation Sensitivity ------------\n",
    "        # Proper approach: perturb the validation feature matrix and compute output changes.\n",
    "        eps = 1e-8\n",
    "        # generate noise scaled per-feature (10% of feature std); tune scale factor if sensitivity too large\n",
    "        per_feature_std = np.std(X_val_scaled, axis=0, ddof=1)\n",
    "        # If a feature std is zero, use small value to avoid zero noise\n",
    "        per_feature_std[per_feature_std == 0] = 1e-6\n",
    "        noise_scale = 0.01  # 1% noise; you can reduce to 0.001 if this is still large\n",
    "        noise = np.random.normal(0, noise_scale * per_feature_std, X_val_scaled.shape).astype(np.float32)\n",
    "        # Perturb the actual validation features\n",
    "        X_val_perturbed = X_val_scaled + noise\n",
    "        # predict with perturbed inputs\n",
    "        y_perturbed = lstm_model.predict(X_val_perturbed.reshape((X_val_perturbed.shape[0], X_val_perturbed.shape[1], 1)), verbose=0).flatten()\n",
    "        if target_scale_for_lstm:\n",
    "            y_perturbed = y_scaler.inverse_transform(y_perturbed.reshape(-1,1)).reshape(-1)\n",
    "        # relative change metric, averaged\n",
    "        sensitivity = np.mean(np.abs(y_perturbed - lstm_val_pred) / (np.abs(lstm_val_pred) + eps))\n",
    "\n",
    "        # Metrics\n",
    "        rmse_prophet = np.sqrt(mean_squared_error(y_val, prophet_val_pred))\n",
    "        r2_prophet = r2_score(y_val, prophet_val_pred)\n",
    "        rmse_lstm = np.sqrt(mean_squared_error(y_val, lstm_val_pred))\n",
    "        r2_lstm = r2_score(y_val, lstm_val_pred)\n",
    "        rmse_final = np.sqrt(mean_squared_error(y_val, hybrid_val_pred))\n",
    "        r2_final = r2_score(y_val, hybrid_val_pred)\n",
    "\n",
    "        print(f\"w={w_opt:.3f} | Prophet R2={r2_prophet:.3f}, LSTM R2={r2_lstm:.3f} | Hybrid R2={r2_final:.3f}\")\n",
    "        print(f\"CPI cov={cpi_cov:.3f}, width={cpi_width:.3f}, q={cpi_q:.4f} | Sensitivity={sensitivity:.4f} | Residual entropy={res_entropy:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'zone': zone,\n",
    "            'w': w_opt,\n",
    "            'rmse_prophet': rmse_prophet, 'r2_prophet': r2_prophet,\n",
    "            'rmse_lstm': rmse_lstm, 'r2_lstm': r2_lstm,\n",
    "            'rmse_final': rmse_final, 'r2_final': r2_final,\n",
    "            'cpi_cov': cpi_cov, 'cpi_width': cpi_width,\n",
    "            'cpi_q': cpi_q,\n",
    "            'res_entropy': res_entropy,\n",
    "            'sensitivity': sensitivity,\n",
    "            'shap_series': shap_series\n",
    "        })\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== Summary Across Zones ===\")\n",
    "    display_cols = ['zone','w','rmse_prophet','r2_prophet','rmse_lstm','r2_lstm','rmse_final','r2_final','cpi_cov','cpi_width','res_entropy','sensitivity']\n",
    "    print(res_df[display_cols].round(4).to_string(index=False))\n",
    "    print(f\"\\nTotal runtime: {time.time()-start_time:.1f}s\")\n",
    "    return res_df\n",
    "\n",
    "# -------------------- Usage --------------------\n",
    "# Ensure `data_hourly_mean` is loaded and accessible as a DataFrame\n",
    "# Example: df = data_hourly_mean.copy(); df.index = pd.to_datetime(df.index)\n",
    "# res_df = run_hybrid(df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14271435,
     "datasetId": 8602599,
     "isSourceIdPinned": false,
     "sourceId": 13545611,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
